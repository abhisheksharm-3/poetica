---
title: Poetica
emoji: ğŸ“š
colorFrom: green
colorTo: indigo
sdk: docker
pinned: false
---

# Poetica - Backend API

FastAPI-based poetry generation API powered by a fine-tuned GPT-2 model.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Start development server
uvicorn main:app --reload --port 8000
```

API available at [http://localhost:8000](http://localhost:8000)

## ğŸ“œ API Reference

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API info and status |
| `/health` | GET | Health check with model status |
| `/generate` | POST | Generate a poem |

### Generate Poem

**Request:**

```bash
curl -X POST http://localhost:8000/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "sunset over the ocean",
    "style": "haiku",
    "temperature": 0.8,
    "max_length": 100
  }'
```

**Parameters:**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `prompt` | string | âœ“ | Topic/theme for the poem |
| `style` | string | | `free_verse`, `haiku`, or `sonnet` |
| `temperature` | float | | Creativity level (0.1-2.0, default: 0.8) |
| `max_length` | int | | Maximum tokens (10-500, default: 100) |

**Response:**

```json
{
  "poem": "Generated poem text...",
  "style": "haiku",
  "tokens_used": 42
}
```

## ğŸ› ï¸ Tech Stack

- **Framework**: FastAPI 0.109
- **Server**: Uvicorn / Gunicorn
- **ML Framework**: PyTorch 2.3, Transformers 4.43
- **Validation**: Pydantic 2.6
- **Rate Limiting**: SlowAPI

## ğŸ“ Project Structure

```
server/
â”œâ”€â”€ main.py                 # FastAPI entry point
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/               # Route handlers
â”‚   â”‚   â””â”€â”€ routes.py      # API endpoints
â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â”œâ”€â”€ poetry.py      # Poem generation
â”‚   â”‚   â””â”€â”€ model.py       # Model loading
â”‚   â”œâ”€â”€ models/            # Pydantic schemas
â”‚   â”‚   â””â”€â”€ schemas.py     # Request/Response models
â”‚   â”œâ”€â”€ config/            # Settings
â”‚   â”‚   â””â”€â”€ settings.py    # Environment config
â”‚   â””â”€â”€ middleware/        # Middleware
â”‚       â””â”€â”€ rate_limit.py  # Rate limiting
â”œâ”€â”€ models/                 # GPT-2 model files
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ Dockerfile              # Multi-stage Docker build
```

## âš™ï¸ Environment Variables

Create a `.env` file:

```env
CORS_ORIGINS=http://localhost:3000,https://poetica-ai.vercel.app
RATE_LIMIT_REQUESTS=10
MAX_CONCURRENT_REQUESTS=4
```

| Variable | Default | Description |
|----------|---------|-------------|
| `CORS_ORIGINS` | `*` | Allowed CORS origins (comma-separated) |
| `RATE_LIMIT_REQUESTS` | `10` | Max requests per minute per IP |
| `MAX_CONCURRENT_REQUESTS` | `4` | Max concurrent generation requests |

## ğŸ³ Docker Deployment

```bash
# Build image
docker build -t poetica-server .

# Run container
docker run -p 7860:7860 poetica-server
```

### Hugging Face Spaces

This project is configured for deployment on [Hugging Face Spaces](https://huggingface.co/spaces) using Docker SDK:

1. Create a new Space with Docker SDK
2. Push the repository
3. The model will auto-download on first request

## ğŸ§  Model Information

- **Base Model**: GPT-2
- **Fine-tuned for**: Poetry generation
- **Training**: [Kaggle Notebook](https://www.kaggle.com/code/abhisheksan1/notebookc1613fb160)

The model is automatically downloaded to `models/` directory on first startup.

## ğŸ“Š Rate Limiting

| Limit | Value |
|-------|-------|
| Requests/minute | 10 (configurable) |
| Concurrent requests | 4 (configurable) |

Rate limits are enforced per IP address using SlowAPI.

## ğŸ”§ Development

```bash
# Install dev dependencies
pip install -r requirements.txt

# Run with auto-reload
uvicorn main:app --reload --port 8000

# Run tests (if available)
pytest
```

## ğŸ“š API Documentation

Interactive API docs available at:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
